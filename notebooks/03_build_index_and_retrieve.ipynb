{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notebook 03: Build FAISS Index & Test Retrieval\n",
        "\n",
        "## Goal\n",
        "\n",
        "Generate embeddings for all chunks, build a FAISS index, and test retrieval with example queries.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## FAISS Index Choice\n",
        "\n",
        "### IndexFlatIP vs IndexFlatL2\n",
        "\n",
        "- **IndexFlatIP (Inner Product)**: Requires normalized vectors; equivalent to cosine similarity\n",
        "- **IndexFlatL2 (Euclidean)**: No normalization needed; measures distance\n",
        "\n",
        "We'll use **IndexFlatIP** with normalized embeddings because:\n",
        "\n",
        "- Better semantic matching for text (cosine similarity)\n",
        "- Faster search for normalized vectors\n",
        "- Standard practice in semantic search\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Normalization & Search Latency\n",
        "\n",
        "- **Normalization**: Ensure all embeddings are L2-normalized before indexing\n",
        "- **Search latency**: IndexFlatIP is exact (no approximation), so search is O(n) but fast enough for our corpus size\n",
        "- **Future scaling**: For larger corpora, consider IndexIVFFlat or HNSW for approximate search\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Metadata Format for Citations\n",
        "\n",
        "Each chunk's metadata should include:\n",
        "\n",
        "- `book`: Source book name (e.g., \"iliad\", \"dorian\")\n",
        "- `para_idx_start`: First paragraph index in this chunk\n",
        "- `para_idx_end`: Last paragraph index in this chunk\n",
        "- `chunk_id`: Unique identifier for the chunk\n",
        "- `char_span`: Character start/end positions (optional, for precise citations)\n",
        "\n",
        "This metadata enables us to generate citations like:\n",
        "\n",
        "> \"[1] Quote text...\" — The Iliad, Book 1, paragraphs 5-7\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Load Chunks from Previous Notebook\n",
        "\n",
        "Load the chunked data (or regenerate if needed).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load chunks (either from memory or saved intermediate file)\n",
        "# If needed, re-run chunking from notebook 02.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Build Full Embeddings & FAISS Index\n",
        "\n",
        "Embed all chunks and build the FAISS index.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === TODO (you code this) ===\n",
        "# Build full embeddings and FAISS index; persist to data/index/.\n",
        "\n",
        "from src.embed_index import embed_texts, build_faiss_index, save_index\n",
        "\n",
        "# 1. Embed all chunk texts\n",
        "# 2. Build FAISS index (IndexFlatIP with normalized vectors)\n",
        "# 3. Save index and metadata to data/index/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Load Index & Test Retrieval\n",
        "\n",
        "Load the saved index and test retrieval with example queries.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === TODO (you code this) ===\n",
        "# Load index & metadata; test a few queries.\n",
        "\n",
        "from src.embed_index import load_index\n",
        "from src.retrieve import retrieve\n",
        "\n",
        "# 1. Load index and metadata\n",
        "# 2. Load embedding model\n",
        "# 3. Test retrieval with example queries\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example Queries & Manual Relevance Check\n",
        "\n",
        "Test with queries like:\n",
        "\n",
        "- \"How does Homer portray Achilles' anger in Book 1?\"\n",
        "- \"What does Lord Henry claim about influence on the young?\"\n",
        "- \"Where does the poem describe the shield of Achilles?\"\n",
        "\n",
        "For each query, manually judge whether the retrieved snippets are relevant. This helps validate:\n",
        "\n",
        "1. Embedding quality (semantic similarity)\n",
        "2. Chunk size appropriateness (not too fragmented, not too broad)\n",
        "3. Retrieval ranking (most relevant chunks appear first)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test queries and display top-k results\n",
        "# For each query, show:\n",
        "# - Query text\n",
        "# - Top 3-5 retrieved chunks with scores\n",
        "# - Manual relevance judgment (relevant/partially relevant/not relevant)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "At this point, you should have:\n",
        "\n",
        "- ✅ Full FAISS index built and saved to `data/index/`\n",
        "- ✅ Metadata persisted alongside the index\n",
        "- ✅ Retrieval tested with example queries\n",
        "- ✅ Manual validation that retrieved chunks are relevant\n",
        "\n",
        "**Next notebook**: Build a small QA evaluation set, test answer composition, and wire up the Gradio demo.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
